{% extends "base.html" %}

{% block title %}Voice AI Mentor - Aarohan{% endblock %}

{% block head %}
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<style>
/* Voice Chat Specific Styles */
.voice-chat-container {
    background: linear-gradient(135deg, rgba(76, 29, 149, 0.1), rgba(124, 58, 237, 0.05));
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.1);
}

.message-bubble {
    backdrop-filter: blur(8px);
    border: 1px solid rgba(255, 255, 255, 0.1);
}

.user-message {
    background: linear-gradient(135deg, rgba(147, 51, 234, 0.2), rgba(99, 102, 241, 0.1));
}

.ai-message {
    background: linear-gradient(135deg, rgba(16, 185, 129, 0.2), rgba(6, 214, 160, 0.1));
}

.voice-controls {
    background: rgba(30, 41, 59, 0.4);
    backdrop-filter: blur(8px);
    border: 1px solid rgba(255, 255, 255, 0.1);
}

.voice-visualizer {
    background: linear-gradient(45deg, #4f46e5, #7c3aed, #ec4899);
}

.recording-animation {
    animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}

@keyframes pulse {
    0%, 100% {
        opacity: 1;
        transform: scale(1);
    }
    50% {
        opacity: 0.5;
        transform: scale(1.05);
    }
}

/* Toggle Switch Styles */
.toggle-switch {
    position: relative;
    display: inline-block;
    width: 60px;
    height: 34px;
}

.toggle-switch input {
    opacity: 0;
    width: 0;
    height: 0;
}

.toggle-slider {
    position: absolute;
    cursor: pointer;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background-color: #4b5563;
    transition: .4s;
    border-radius: 34px;
}

.toggle-slider:before {
    position: absolute;
    content: "";
    height: 26px;
    width: 26px;
    left: 4px;
    bottom: 4px;
    background-color: white;
    transition: .4s;
    border-radius: 50%;
}

input:checked + .toggle-slider {
    background-color: #10b981;
}

input:focus + .toggle-slider {
    box-shadow: 0 0 1px #10b981;
}

input:checked + .toggle-slider:before {
    transform: translateX(26px);
}

.toggle-label {
    display: flex;
    align-items: center;
    gap: 8px;
    font-size: 14px;
    color: #e5e7eb;
}

.audio-wave {
    display: flex;
    align-items: center;
    gap: 2px;
}

.wave-bar {
    width: 3px;
    background: linear-gradient(to top, #4f46e5, #7c3aed);
    border-radius: 2px;
    animation: wave 1.5s ease-in-out infinite;
}

.wave-bar:nth-child(1) { height: 10px; animation-delay: 0s; }
.wave-bar:nth-child(2) { height: 15px; animation-delay: 0.1s; }
.wave-bar:nth-child(3) { height: 8px; animation-delay: 0.2s; }
.wave-bar:nth-child(4) { height: 20px; animation-delay: 0.3s; }
.wave-bar:nth-child(5) { height: 12px; animation-delay: 0.4s; }

@keyframes wave {
    0%, 100% { height: 10px; }
    50% { height: 25px; }
}

.analysis-card {
    background: rgba(30, 41, 59, 0.3);
    backdrop-filter: blur(6px);
    border: 1px solid rgba(255, 255, 255, 0.1);
}

.sentiment-positive { color: #10b981; }
.sentiment-negative { color: #ef4444; }
.sentiment-neutral { color: #f59e0b; }
</style>
{% endblock %}

{% block content %}
<div class="min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 py-8">
    <!-- Header -->
    <div class="max-w-6xl mx-auto px-4 mb-8">
        <div class="text-center">
            <h1 class="text-4xl font-bold text-white mb-4">
                üé§ Voice AI Mentor
            </h1>
            <p class="text-xl text-gray-300 mb-6">
                Speak your thoughts, get AI-powered insights and guidance
            </p>
        </div>
    </div>

    <div class="max-w-6xl mx-auto px-4">
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
            <!-- Voice Chat Interface -->
            <div class="lg:col-span-2">
                <div class="voice-chat-container rounded-xl p-6 h-[600px] flex flex-col">
                    <!-- Chat Messages -->
                    <div id="chatMessages" class="flex-1 overflow-y-auto mb-4 space-y-4">
                        <div class="ai-message message-bubble rounded-xl p-4 max-w-[80%]">
                            <div class="flex items-start space-x-3">
                                <div class="w-8 h-8 bg-green-500 rounded-full flex items-center justify-center text-white font-semibold">
                                    AI
                                </div>
                                <div>
                                    <p class="text-white">Hello! I'm your AI voice mentor. üéØ Start **Conversation Mode** above for natural, real-time dialogue in your preferred language. Just speak naturally and I'll listen and respond automatically! How are you feeling today?</p>
                                    <span class="text-xs text-gray-400 mt-2 block">Just now</span>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Voice Controls -->
                    <div class="voice-controls rounded-xl p-4">
                        <!-- Primary Conversation Mode -->
                        <div class="text-center mb-4">
                            <button id="conversationModeBtn" class="w-20 h-20 bg-gradient-to-br from-green-500 to-blue-600 rounded-full flex items-center justify-center hover:from-green-600 hover:to-blue-700 transition-all duration-300 focus:outline-none focus:ring-4 focus:ring-green-300 shadow-lg mx-auto">
                                <svg class="w-10 h-10 text-white" fill="currentColor" viewBox="0 0 24 24">
                                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                                    <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                                </svg>
                            </button>
                            <div class="mt-2">
                                <div class="text-lg font-semibold text-white">üéØ Conversation Mode</div>
                                <div class="text-sm text-gray-300">Natural, real-time AI conversation</div>
                            </div>
                        </div>
                        
                        <div class="flex items-center justify-between">
                            <div class="flex items-center space-x-4">
                                <div id="audioVisualizer" class="audio-wave hidden">
                                    <div class="wave-bar"></div>
                                    <div class="wave-bar"></div>
                                    <div class="wave-bar"></div>
                                    <div class="wave-bar"></div>
                                    <div class="wave-bar"></div>
                                </div>
                                
                                <div id="recordingStatus" class="text-gray-300">
                                    <span id="statusText">Start natural conversation above</span>
                                    <div id="conversationModeStatus" class="text-xs text-green-400 mt-1 hidden">
                                        üéØ Real-time conversation active
                                    </div>
                                </div>
                            </div>
                            
                            <div class="flex items-center space-x-4 flex-wrap">
                                <select id="languageSelect" class="px-3 py-1 bg-gray-700 text-white rounded-lg text-sm border border-gray-600">
                                    <option value="en-US">English (US)</option>
                                    <option value="en-GB">English (UK)</option>
                                    <option value="hi-IN">‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi)</option>
                                    <option value="te-IN">‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)</option>
                                    <option value="kn-IN">‡≤ï‡≤®‡≥ç‡≤®‡≤° (Kannada)</option>
                                </select>
                                
                                <!-- Manual Options Toggle Switch -->
                                <div class="toggle-label">
                                    <span>Manual Options</span>
                                    <label class="toggle-switch">
                                        <input type="checkbox" id="toggleManualControls">
                                        <span class="toggle-slider"></span>
                                    </label>
                                    <span id="toggleStatus" class="text-xs text-gray-400">OFF</span>
                                </div>
                                
                                <button id="clearChat" class="px-4 py-2 bg-gray-600 text-white rounded-lg hover:bg-gray-700 transition-colors">
                                    Clear Chat
                                </button>
                                <button id="testMic" class="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors">
                                    üé§ Test Mic
                                </button>
                            </div>
                        </div>
                        
                        <!-- Optional Manual Controls (Collapsible) -->
                        <div id="manualControls" class="mt-4 hidden border-t border-gray-600 pt-4">
                            <div class="text-sm text-gray-400 mb-3">Optional: Manual recording and playback controls</div>
                            <div class="flex items-center space-x-4">
                                <button id="recordBtn" class="w-12 h-12 bg-gradient-to-br from-red-500 to-pink-600 rounded-full flex items-center justify-center hover:from-red-600 hover:to-pink-700 transition-all duration-300 focus:outline-none focus:ring-2 focus:ring-red-300">
                                    <svg class="w-6 h-6 text-white" fill="currentColor" viewBox="0 0 24 24">
                                        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                                        <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                                    </svg>
                                </button>
                                <button id="speakBtn" class="px-3 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors disabled:opacity-50 disabled:cursor-not-allowed text-sm" disabled>
                                    üîä Speak Response
                                </button>
                                <span class="text-xs text-gray-400">Manual record & playback</span>
                            </div>
                        </div>
                        
                        <!-- Recording Progress -->
                        <div id="recordingProgress" class="mt-4 hidden">
                            <div class="w-full bg-gray-700 rounded-full h-2">
                                <div id="progressBar" class="bg-gradient-to-r from-red-500 to-pink-600 h-2 rounded-full" style="width: 0%"></div>
                            </div>
                            <p class="text-sm text-gray-400 mt-2">Recording... <span id="recordingTime">0:00</span></p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Analysis Panel -->
            <div class="space-y-6">
                <!-- Real-time Analysis -->
                <div class="analysis-card rounded-xl p-6">
                    <h3 class="text-lg font-semibold text-white mb-4 flex items-center">
                        üìä Speech Analysis
                    </h3>
                    
                    <div class="space-y-4">
                        <div>
                            <label class="text-sm text-gray-400">Sentiment</label>
                            <div id="sentimentDisplay" class="text-lg font-semibold sentiment-neutral">
                                Neutral
                            </div>
                        </div>
                        
                        <div>
                            <label class="text-sm text-gray-400">Confidence</label>
                            <div class="flex items-center space-x-2 mt-1">
                                <div class="flex-1 bg-gray-700 rounded-full h-2">
                                    <div id="confidenceBar" class="bg-blue-500 h-2 rounded-full" style="width: 0%"></div>
                                </div>
                                <span id="confidenceText" class="text-sm text-white">0%</span>
                            </div>
                        </div>
                        
                        <div>
                            <label class="text-sm text-gray-400">Emotional State</label>
                            <div id="emotionDisplay" class="text-white font-medium">
                                -
                            </div>
                        </div>
                        
                        <div>
                            <label class="text-sm text-gray-400">Keywords</label>
                            <div id="keywordsDisplay" class="flex flex-wrap gap-2 mt-2">
                                <!-- Keywords will be populated here -->
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Conversation Stats -->
                <div class="analysis-card rounded-xl p-6">
                    <h3 class="text-lg font-semibold text-white mb-4">üìà Session Stats</h3>
                    
                    <div class="space-y-3">
                        <div class="flex justify-between">
                            <span class="text-gray-400">Messages:</span>
                            <span id="messageCount" class="text-white font-medium">0</span>
                        </div>
                        <div class="flex justify-between">
                            <span class="text-gray-400">Duration:</span>
                            <span id="sessionDuration" class="text-white font-medium">0:00</span>
                        </div>
                        <div class="flex justify-between">
                            <span class="text-gray-400">Avg Sentiment:</span>
                            <span id="avgSentiment" class="text-white font-medium">Neutral</span>
                        </div>
                    </div>
                </div>

                <!-- Quick Actions -->
                <div class="analysis-card rounded-xl p-6">
                    <h3 class="text-lg font-semibold text-white mb-4">‚ö° Quick Actions</h3>
                    
                    <div class="space-y-2">
                        <button onclick="askQuestion('How are you feeling today?')" class="w-full text-left px-3 py-2 text-gray-300 hover:text-white hover:bg-gray-700 rounded-lg transition-colors">
                            üí≠ Ask about feelings
                        </button>
                        <button onclick="askQuestion('What challenges are you facing?')" class="w-full text-left px-3 py-2 text-gray-300 hover:text-white hover:bg-gray-700 rounded-lg transition-colors">
                            üéØ Discuss challenges
                        </button>
                        <button onclick="askQuestion('What are your goals?')" class="w-full text-left px-3 py-2 text-gray-300 hover:text-white hover:bg-gray-700 rounded-lg transition-colors">
                            üéØ Talk about goals
                        </button>
                        <button onclick="requestAdvice()" class="w-full text-left px-3 py-2 text-gray-300 hover:text-white hover:bg-gray-700 rounded-lg transition-colors">
                            üí° Get advice
                        </button>
                    </div>
                </div>

                <!-- Privacy Notice -->
                <div class="analysis-card rounded-xl p-6">
                    <h3 class="text-lg font-semibold text-white mb-4">üîí Privacy & Safety</h3>
                    
                    <div class="space-y-3 text-sm text-gray-300">
                        <p>‚Ä¢ Your voice data is processed securely and not stored permanently</p>
                        <p>‚Ä¢ Conversations are analyzed to provide better mental wellness support</p>
                        <p>‚Ä¢ In crisis situations, please contact emergency services immediately</p>
                        <p>‚Ä¢ This AI mentor supplements but doesn't replace professional counseling</p>
                    </div>
                    
                    <div class="mt-4 p-3 bg-red-900/20 border border-red-500/30 rounded-lg">
                        <p class="text-red-300 text-sm font-medium">üö® Crisis Support</p>
                        <p class="text-red-200 text-xs mt-1">For immediate help, contact your local emergency services or mental health crisis line.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
// Voice AI Chat Implementation
class VoiceAIChat {
    constructor() {
        this.isRecording = false;
        this.isSpeaking = false;
        this.recognition = null;
        this.synthesis = window.speechSynthesis;
        this.messages = [];
        this.sessionStart = Date.now();
        this.totalSentiment = 0;
        this.sentimentCount = 0;
        this.lastAIResponse = null;
        this.recordingTimer = null;
        this.conversationMode = false;
        this.silenceTimer = null;
        this.lastSpeechTime = null;
        this.silenceThreshold = 15000; // 15 seconds of silence before auto-prompt (less aggressive)
        this.isWaitingForSpeech = false;
        
        this.initializeVoiceRecognition();
        this.bindEvents();
        this.updateSessionStats();
        this.updateWelcomeMessage('en-US'); // Initialize with English
    }
    
    getWelcomeMessage(languageCode) {
        const welcomeMessages = {
            'en-US': "Hello! I'm your AI voice mentor. üéØ Start **Conversation Mode** above for natural, real-time dialogue in English. Just speak naturally and I'll listen and respond automatically! How are you feeling today?",
            'en-GB': "Hello! I'm your AI voice mentor. üéØ Start **Conversation Mode** above for natural, real-time dialogue in English. Just speak naturally and I'll listen and respond automatically! How are you feeling today?",
            'hi-IN': "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ AI ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç‡§üŸàÿ± ‡§π‡•Ç‡§Ç‡•§ üéØ ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï, ‡§∞‡§ø‡§Ø‡§≤-‡§ü‡§æ‡§á‡§Æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ä‡§™‡§∞ **‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§Æ‡•ã‡§°** ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§¨‡§∏ ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§∏‡•Å‡§®‡•Ç‡§Ç‡§ó‡§æ ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•Ç‡§Ç‡§ó‡§æ! ‡§Ü‡§ú ‡§Ü‡§™ ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç?",
            'te-IN': "‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä AI ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞Æ‡±Ü‡∞Ç‡∞ü‡∞∞‡±ç‚Äå‡∞®‡∞ø. üéØ ‡∞∏‡∞π‡∞ú‡∞Æ‡±à‡∞®, ‡∞∞‡∞ø‡∞Ø‡∞≤‡±ç-‡∞ü‡±à‡∞Æ‡±ç ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞™‡±à‡∞® **‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£ ‡∞Æ‡±ã‡∞°‡±ç** ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø. ‡∞∏‡∞π‡∞ú‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞®‡±á‡∞®‡±Å ‡∞µ‡∞ø‡∞Ç‡∞ü‡∞æ‡∞®‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∏‡±ç‡∞™‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å! ‡∞à‡∞∞‡±ã‡∞ú‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞≤‡∞æ ‡∞Ö‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?",
            'kn-IN': "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞! ‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ AI ‡≤ß‡≥ç‡≤µ‡≤®‡≤ø ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤¶‡≤∞‡≥ç‡≤∂‡≤ï. üéØ ‡≤®‡≥à‡≤∏‡≤∞‡≥ç‡≤ó‡≤ø‡≤ï, ‡≤®‡≥à‡≤ú-‡≤∏‡≤Æ‡≤Ø‡≤¶ ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤∏‡≤Ç‡≤≠‡≤æ‡≤∑‡≤£‡≥Ü‡≤ó‡≤æ‡≤ó‡≤ø ‡≤Æ‡≥á‡≤≤‡≥Ü **‡≤∏‡≤Ç‡≤≠‡≤æ‡≤∑‡≤£‡≥Ü ‡≤Æ‡≥ã‡≤°‡≥ç** ‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠‡≤ø‡≤∏‡≤ø. ‡≤∏‡≤π‡≤ú‡≤µ‡≤æ‡≤ó‡≤ø ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤ï‡≥á‡≤≥‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤∏‡≥ç‡≤µ‡≤Ø‡≤Ç‡≤ö‡≤æ‡≤≤‡≤ø‡≤§‡≤µ‡≤æ‡≤ó‡≤ø ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü! ‡≤á‡≤Ç‡≤¶‡≥Å ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤π‡≥á‡≤ó‡≥Ü ‡≤Ö‡≤®‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü?"
        };
        
        return welcomeMessages[languageCode] || welcomeMessages['en-US'];
    }
    
    updateWelcomeMessage(languageCode) {
        // Find the initial AI welcome message and update it
        const chatMessages = document.getElementById('chatMessages');
        const firstMessage = chatMessages?.querySelector('.ai-message p');
        
        if (firstMessage) {
            const welcomeText = this.getWelcomeMessage(languageCode);
            firstMessage.innerHTML = welcomeText;
        }
    }
    
    initializeVoiceRecognition() {
        console.log('üé§ Initializing voice recognition...');
        
        if ('webkitSpeechRecognition' in window) {
            console.log('‚úÖ Using webkitSpeechRecognition');
            this.recognition = new webkitSpeechRecognition();
        } else if ('SpeechRecognition' in window) {
            console.log('‚úÖ Using SpeechRecognition');
            this.recognition = new SpeechRecognition();
        } else {
            console.error('‚ùå Speech recognition not supported in this browser');
        }
        
        if (this.recognition) {
            console.log('üé§ Configuring speech recognition...');
            this.recognition.continuous = true;
            this.recognition.interimResults = true;
            this.recognition.lang = 'en-US';
            this.recognition.maxAlternatives = 1;
            
            // Remove grammars configuration for better multilingual support
            console.log('üé§ Speech recognition configured for multilingual support');
            
            this.recognition.onstart = () => {
                console.log('üé§ Recognition started - onstart event fired');
                console.log('üé§ Recognition configuration:');
                console.log('   - Language:', this.recognition.lang);
                console.log('   - Continuous:', this.recognition.continuous);
                console.log('   - Interim results:', this.recognition.interimResults);
                console.log('   - Max alternatives:', this.recognition.maxAlternatives);
                this.onRecordingStart();
            };
            
            this.recognition.onresult = (event) => {
                console.log('üé§ SPEECH RESULT EVENT FIRED!', event);
                console.log('üé§ Recognition language setting:', this.recognition.lang);
                console.log('üé§ Number of results:', event.results.length);
                for (let i = 0; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    const confidence = event.results[i][0].confidence;
                    console.log(`üé§ Result ${i}:`, transcript, 'Final:', event.results[i].isFinal, 'Confidence:', confidence);
                    
                    // Check if this looks like Telugu text
                    if (transcript && /[\u0C00-\u0C7F]/.test(transcript)) {
                        console.log('üéØ Telugu script detected in transcript!');
                    }
                }
                this.onSpeechResult(event);
            };
            
            this.recognition.onerror = (event) => {
                console.error('üö® SPEECH RECOGNITION ERROR:', event.error);
                console.error('üö® Error details:', event);
                this.onRecordingError(event);
            };
            
            this.recognition.onend = () => {
                this.onRecordingEnd();
            };
        } else {
            this.showMessage('ai', 'Speech recognition is not supported in your browser. Please try Chrome, Edge, or Safari for the best experience.');
        }
    }
    
    bindEvents() {
        const recordBtn = document.getElementById('recordBtn');
        const speakBtn = document.getElementById('speakBtn');
        const clearBtn = document.getElementById('clearChat');
        const languageSelect = document.getElementById('languageSelect');
        const conversationModeBtn = document.getElementById('conversationModeBtn');
        
        if (recordBtn) {
            recordBtn.addEventListener('click', (e) => {
                e.preventDefault();
                this.toggleRecording();
            });
        }
        
        if (speakBtn) {
            speakBtn.addEventListener('click', (e) => {
                e.preventDefault();
                this.speakLastResponse();
            });
        }
        
        if (clearBtn) {
            clearBtn.addEventListener('click', (e) => {
                e.preventDefault();
                this.clearChat();
            });
        }
        
        const testMicBtn = document.getElementById('testMic');
        if (testMicBtn) {
            testMicBtn.addEventListener('click', (e) => {
                e.preventDefault();
                this.testMicrophone();
            });
        }
        
        if (languageSelect) {
            languageSelect.addEventListener('change', (e) => {
                this.changeLanguage(e.target.value);
            });
        }
        
        if (conversationModeBtn) {
            conversationModeBtn.addEventListener('click', (e) => {
                e.preventDefault();
                this.toggleConversationMode();
            });
        }
        
        // Toggle manual controls
        const toggleManualControls = document.getElementById('toggleManualControls');
        if (toggleManualControls) {
            toggleManualControls.addEventListener('change', (e) => {
                this.toggleManualControls();
            });
        }
    }
    
    changeLanguage(languageCode) {
        if (this.recognition) {
            // Temporarily stop any active recording to prevent conflicts
            const wasInConversationMode = this.conversationMode;
            if (this.isRecording) {
                this.stopRecording();
            }
            
            // Update speech recognition language
            this.recognition.lang = languageCode;
            console.log(`üé§ Speech recognition language changed to: ${languageCode}`);
            
            // Enhanced language-specific configuration
            if (languageCode === 'te-IN') {
                console.log('üéØ Telugu language selected - configuring optimal recognition settings');
                this.recognition.lang = 'te-IN';
                // For Telugu, use more alternatives and interim results for better accuracy
                this.recognition.maxAlternatives = 3;
                this.recognition.interimResults = true;
                console.log('üéØ Telugu recognition optimized: maxAlternatives=3, interimResults=true');
            } else if (languageCode === 'hi-IN') {
                console.log('üéØ Hindi language selected - configuring optimal recognition settings');
                this.recognition.lang = 'hi-IN';
                this.recognition.maxAlternatives = 2;
                this.recognition.interimResults = true;
            } else if (languageCode === 'kn-IN') {
                console.log('üéØ Kannada language selected - configuring optimal recognition settings');
                this.recognition.lang = 'kn-IN';
                this.recognition.maxAlternatives = 2;
                this.recognition.interimResults = true;
            } else {
                // English or other languages
                this.recognition.maxAlternatives = 1;
                this.recognition.interimResults = true;
            }
            
            // Force recognition to restart with new language if in conversation mode
            if (wasInConversationMode && this.recognition) {
                console.log('üîÑ Restarting recognition with new language');
                try {
                    this.recognition.stop();
                } catch (e) {
                    console.log('Recognition already stopped');
                }
            }
            
            // Update welcome message to new language
            this.updateWelcomeMessage(languageCode);
            
            // Show confirmation message in the selected language
            const confirmationMessages = {
                'en-US': 'Voice recognition language changed to English (US). You can now speak in English!',
                'en-GB': 'Voice recognition language changed to English (UK). You can now speak in English!',
                'hi-IN': '‡§Ü‡§µ‡§æ‡§ú ‡§™‡§π‡§ö‡§æ‡§® ‡§≠‡§æ‡§∑‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§ó‡§à‡•§ ‡§Ö‡§¨ ‡§Ü‡§™ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç!',
                'te-IN': '‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞∞‡∞ø‡∞ï‡∞ó‡±ç‡∞®‡∞ø‡∞∑‡∞®‡±ç ‡∞≠‡∞æ‡∞∑ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞ï‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞µ‡∞ö‡±ç‡∞ö‡±Å!',
                'kn-IN': '‡≤ß‡≥ç‡≤µ‡≤®‡≤ø ‡≤ó‡≥Å‡≤∞‡≥Å‡≤§‡≤ø‡≤∏‡≥Å‡≤µ‡≤ø‡≤ï‡≥Ü ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤¨‡≤¶‡≤≤‡≤æ‡≤Ø‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤à‡≤ó ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤¨‡≤π‡≥Å‡≤¶‡≥Å!'
            };
            
            const confirmationMessage = confirmationMessages[languageCode] || confirmationMessages['en-US'];
            console.log(`DEBUG: Showing confirmation in ${languageCode}: ${confirmationMessage}`);
            
            // Clear any pending automatic prompts or messages
            clearTimeout(this.silenceTimer);
            
            // Show the confirmation message
            this.showMessage('ai', confirmationMessage);
            
            // Speak the confirmation message in the new language
            this.speakResponse(confirmationMessage);
            
            // If we were in conversation mode, restart it after speaking confirmation
            if (wasInConversationMode) {
                // Wait for the TTS to finish before restarting
                setTimeout(() => {
                    if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                        console.log(`üîÑ Restarting conversation mode with ${languageCode} language`);
                        this.startRecording();
                    }
                }, 4000); // Longer delay to let TTS finish
            }
        }
    }
    
    toggleConversationMode() {
        this.conversationMode = !this.conversationMode;
        console.log('üéØ Conversation mode toggled to:', this.conversationMode);
        const conversationModeBtn = document.getElementById('conversationModeBtn');
        const statusText = document.getElementById('statusText');
        const conversationModeStatus = document.getElementById('conversationModeStatus');
        
        if (this.conversationMode) {
            // Enable conversation mode - update the large button
            conversationModeBtn.classList.remove('from-green-500', 'to-blue-600', 'hover:from-green-600', 'hover:to-blue-700');
            conversationModeBtn.classList.add('from-red-500', 'to-red-600', 'hover:from-red-600', 'hover:to-red-700');
            
            // Update button content
            conversationModeBtn.innerHTML = `
                <svg class="w-10 h-10 text-white" fill="currentColor" viewBox="0 0 24 24">
                    <path d="M6 6h12v12H6z"/>
                </svg>`;
            
            // Update text below button
            const conversationText = conversationModeBtn.parentElement.querySelector('.text-lg');
            if (conversationText) conversationText.textContent = 'üîá Stop Conversation';
            
            if (statusText) statusText.textContent = 'üéØ Conversation active - Speaking naturally!';
            if (conversationModeStatus) conversationModeStatus.classList.remove('hidden');
            
            const selectedLanguageCode = document.getElementById('languageSelect')?.value || 'en-US';
            const activationMessages = {
                'en-US': 'üéØ Conversation mode activated! I\'m now listening. Please tell me how you\'re feeling or what\'s on your mind.',
                'en-GB': 'üéØ Conversation mode activated! I\'m now listening. Please tell me how you\'re feeling or what\'s on your mind.',
                'hi-IN': 'üéØ ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§Æ‡•ã‡§° ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø! ‡§Æ‡•à‡§Ç ‡§Ö‡§¨ ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç ‡§ï‡§ø ‡§Ü‡§™ ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§Æ‡§® ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§',
                'te-IN': 'üéØ ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£ ‡∞Æ‡±ã‡∞°‡±ç ‡∞∏‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø‡∞Ç! ‡∞®‡±á‡∞®‡±Å ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞µ‡∞ø‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞≤‡∞æ ‡∞Ö‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±ã ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡±Ä ‡∞Æ‡∞®‡∞∏‡±Å‡∞≤‡±ã ‡∞è‡∞Æ‡∞ø ‡∞â‡∞Ç‡∞¶‡±ã ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø.',
                'kn-IN': 'üéØ ‡≤∏‡≤Ç‡≤≠‡≤æ‡≤∑‡≤£‡≥Ü ‡≤Æ‡≥ã‡≤°‡≥ç ‡≤∏‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø! ‡≤®‡≤æ‡≤®‡≥Å ‡≤à‡≤ó ‡≤ï‡≥á‡≤≥‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤π‡≥á‡≤ó‡≥Ü ‡≤Ö‡≤®‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤®‡≤∏‡≥ç‡≤∏‡≤ø‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤è‡≤®‡≤ø‡≤¶‡≥Ü ‡≤é‡≤Ç‡≤¶‡≥Å ‡≤π‡≥á‡≤≥‡≤ø.'
            };
            this.showMessage('ai', activationMessages[selectedLanguageCode] || activationMessages['en-US']);
            
            // Speak the activation message and start listening
            const activationMessage = activationMessages[selectedLanguageCode] || activationMessages['en-US'];
            this.speakResponse(activationMessage, () => {
                // After speaking activation, just start listening - no automatic questions
                setTimeout(() => {
                    if (this.conversationMode && !this.isRecording) {
                        console.log('üé§ Activation complete - starting to listen for user input');
                        this.startRecording();
                        this.startSilenceDetection();
                    }
                }, 1000);
            });
            
            // Note: Listening will start after the activation message is spoken
            
        } else {
            // Disable conversation mode - restore original button
            conversationModeBtn.classList.remove('from-red-500', 'to-red-600', 'hover:from-red-600', 'hover:to-red-700');
            conversationModeBtn.classList.add('from-green-500', 'to-blue-600', 'hover:from-green-600', 'hover:to-blue-700');
            
            // Restore microphone icon
            conversationModeBtn.innerHTML = `
                <svg class="w-10 h-10 text-white" fill="currentColor" viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                    <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                </svg>`;
            
            // Update text below button
            const conversationText = conversationModeBtn.parentElement.querySelector('.text-lg');
            if (conversationText) conversationText.textContent = 'üéØ Conversation Mode';
            
            if (statusText) statusText.textContent = 'Start natural conversation above';
            if (conversationModeStatus) conversationModeStatus.classList.add('hidden');
            
            const selectedLanguageCode = document.getElementById('languageSelect')?.value || 'en-US';
            const deactivationMessages = {
                'en-US': '‚èπÔ∏è Real-time conversation mode disabled. Use the manual options below to record manually.',
                'en-GB': '‚èπÔ∏è Real-time conversation mode disabled. Use the manual options below to record manually.',
                'hi-IN': '‚èπÔ∏è ‡§∞‡§ø‡§Ø‡§≤-‡§ü‡§æ‡§á‡§Æ ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§Æ‡•ã‡§° ‡§®‡§ø‡§∑‡•ç‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§ ‡§Æ‡•à‡§®‡•ç‡§Ø‡•Å‡§Ö‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡•Ä‡§ö‡•á ‡§Æ‡•à‡§®‡•ç‡§Ø‡•Å‡§Ö‡§≤ ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§',
                'te-IN': '‚èπÔ∏è ‡∞∞‡∞ø‡∞Ø‡∞≤‡±ç-‡∞ü‡±à‡∞Æ‡±ç ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£ ‡∞Æ‡±ã‡∞°‡±ç ‡∞®‡∞ø‡∞∑‡±ç‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø‡∞Ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡∞æ‡∞®‡±ç‡∞Ø‡±Å‡∞µ‡∞≤‡±ç ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞¶‡∞ø‡∞ó‡±Å‡∞µ ‡∞Æ‡∞æ‡∞®‡±ç‡∞Ø‡±Å‡∞µ‡∞≤‡±ç ‡∞é‡∞Ç‡∞™‡∞ø‡∞ï‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø‡•§',
                'kn-IN': '‚èπÔ∏è ‡≤®‡≥à‡≤ú-‡≤∏‡≤Æ‡≤Ø ‡≤∏‡≤Ç‡≤≠‡≤æ‡≤∑‡≤£‡≥Ü ‡≤Æ‡≥ã‡≤°‡≥ç ‡≤®‡≤ø‡≤∑‡≥ç‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤π‡≤∏‡≥ç‡≤§‡≤ö‡≤æ‡≤≤‡≤ø‡≤§ ‡≤∞‡≥Ü‡≤ï‡≤æ‡≤∞‡≥ç‡≤°‡≤ø‡≤Ç‡≤ó‡≥ç‚Äå‡≤ó‡≤æ‡≤ó‡≤ø ‡≤ï‡≥Ü‡≤≥‡≤ó‡≤ø‡≤® ‡≤π‡≤∏‡≥ç‡≤§‡≤ö‡≤æ‡≤≤‡≤ø‡≤§ ‡≤Ü‡≤Ø‡≥ç‡≤ï‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤¨‡≤≥‡≤∏‡≤ø‡•§'
            };
            this.showMessage('ai', deactivationMessages[selectedLanguageCode] || deactivationMessages['en-US']);
            
            // Stop any ongoing recording and clear silence detection
            if (this.isRecording) {
                this.stopRecording();
            }
            this.clearSilenceTimer();
            this.isWaitingForSpeech = false;
        }
    }
    
    toggleManualControls() {
        const manualControls = document.getElementById('manualControls');
        const toggleCheckbox = document.getElementById('toggleManualControls');
        const toggleStatus = document.getElementById('toggleStatus');
        
        if (toggleCheckbox.checked) {
            manualControls.classList.remove('hidden');
            toggleStatus.textContent = 'ON';
            toggleStatus.classList.remove('text-gray-400');
            toggleStatus.classList.add('text-green-400');
        } else {
            manualControls.classList.add('hidden');
            toggleStatus.textContent = 'OFF';
            toggleStatus.classList.remove('text-green-400');
            toggleStatus.classList.add('text-gray-400');
        }
    }
    
    toggleRecording() {
        if (!this.recognition) {
            this.showMessage('ai', 'Speech recognition is not supported in your browser. Please try Chrome, Edge, or Safari.');
            return;
        }
        
        if (this.isRecording) {
            this.stopRecording();
        } else {
            this.startRecording();
        }
    }
    
    startRecording() {
        if (!this.recognition) {
            this.showMessage('ai', 'Speech recognition is not supported in your browser. Please try Chrome, Edge, or Safari.');
            return;
        }
        
        if (this.isRecording) {
            console.log('üé§ Already recording, skipping start request');
            return;
        }
        
        try {
            console.log(`üé§ Starting recording - Conversation mode: ${this.conversationMode}`);
            console.log(`üé§ Recognition state - continuous: ${this.recognition.continuous}, interimResults: ${this.recognition.interimResults}`);
            console.log(`üé§ Recognition language: ${this.recognition.lang}`);
            
            // Force update UI to show that we're trying to start
            if (this.conversationMode) {
                const statusText = document.getElementById('statusText');
                if (statusText) statusText.textContent = 'üé§ Starting conversation mode...';
            }
            
            this.recognition.start();
            console.log('üé§ Recognition.start() called successfully');
            
            // Add timeout to detect if recognition doesn't start
            if (this.conversationMode) {
                setTimeout(() => {
                    if (!this.isRecording && this.conversationMode) {
                        console.log('‚ö†Ô∏è Recognition did not start within 3 seconds, trying again...');
                        this.showMessage('ai', 'üîÑ Retrying microphone activation...');
                        setTimeout(() => this.startRecording(), 500);
                    }
                }, 3000);
            }
        } catch (error) {
            console.error('Error starting recognition:', error);
            if (error.name === 'InvalidStateError') {
                console.log('üîÑ Recognition already running, continuing...');
                // In conversation mode, try to restart after a brief pause
                if (this.conversationMode) {
                    setTimeout(() => {
                        if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                            console.log('üîÑ Attempting to restart recognition in conversation mode');
                            try {
                                this.recognition.stop();
                                setTimeout(() => this.startRecording(), 500);
                            } catch (e) {
                                console.error('Error restarting recognition:', e);
                            }
                        }
                    }, 1000);
                } else {
                    this.showMessage('ai', 'Voice recognition is already active.');
                }
            } else {
                this.showMessage('ai', 'Could not start voice recording. Please check your microphone permissions.');
            }
        }
    }
    
    stopRecording() {
        try {
            if (this.recognition && this.isRecording) {
                console.log(`üõë Stopping recording - Conversation mode: ${this.conversationMode}`);
                this.recognition.stop();
            }
        } catch (error) {
            console.error('Error stopping recognition:', error);
        }
        this.isRecording = false;
        this.updateRecordingUI(false);
    }
    
    onRecordingStart() {
        console.log('üé§ onRecordingStart called - setting isRecording to true');
        this.isRecording = true;
        this.updateRecordingUI(true);
        this.startRecordingTimer();
    }
    
    updateRecordingUI(isRecording) {
        const recordBtn = document.getElementById('recordBtn');
        const statusText = document.getElementById('statusText');
        const audioVisualizer = document.getElementById('audioVisualizer');
        const recordingProgress = document.getElementById('recordingProgress');
        
        // In conversation mode, keep UI more subtle
        if (this.conversationMode) {
            // Don't show recording animation in conversation mode - too distracting
            recordBtn.classList.remove('recording-animation');
            recordBtn.innerHTML = `
                <svg class="w-8 h-8 text-white" fill="currentColor" viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                    <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                </svg>
            `;
            recordBtn.title = 'Microphone (Conversation mode active)';
            recordBtn.disabled = true; // Disable manual control in conversation mode
            
            // Hide visual indicators in conversation mode
            if (audioVisualizer) audioVisualizer.classList.add('hidden');
            if (recordingProgress) recordingProgress.classList.add('hidden');
            
            if (isRecording) {
                if (statusText) statusText.textContent = 'üé§ Listening... Speak naturally';
            } else {
                if (statusText) statusText.textContent = 'üéØ Conversation mode - Ready to listen';
            }
        } else {
            // Normal mode - show full recording UI
            recordBtn.disabled = false;
            
            if (isRecording) {
                recordBtn.classList.add('recording-animation');
                recordBtn.innerHTML = `
                    <svg class="w-8 h-8 text-white" fill="currentColor" viewBox="0 0 24 24">
                        <rect x="6" y="6" width="12" height="12" rx="2"/>
                    </svg>
                `;
                recordBtn.title = 'Click to stop recording';
                
                if (statusText) statusText.textContent = 'Listening... Speak now';
                if (audioVisualizer) audioVisualizer.classList.remove('hidden');
                if (recordingProgress) recordingProgress.classList.remove('hidden');
            } else {
                recordBtn.classList.remove('recording-animation');
                recordBtn.innerHTML = `
                    <svg class="w-8 h-8 text-white" fill="currentColor" viewBox="0 0 24 24">
                        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                        <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                    </svg>
                `;
                recordBtn.title = 'Click to start recording';
                
                if (statusText) statusText.textContent = 'Click to start recording';
                if (audioVisualizer) audioVisualizer.classList.add('hidden');
                if (recordingProgress) recordingProgress.classList.add('hidden');
            }
        }
    }
    
    onRecordingEnd() {
        this.isRecording = false;
        this.updateRecordingUI(false);
        if (this.recordingTimer) {
            clearInterval(this.recordingTimer);
            this.recordingTimer = null;
        }
        
        // In conversation mode, automatically restart recording after processing
        if (this.conversationMode && !this.isSpeaking) {
            console.log('üîÑ Conversation mode: Auto-restarting recording after speech ends');
            setTimeout(() => {
                if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                    this.startRecording();
                }
            }, 1000); // Give 1 second for processing to start
        }
    }
    
    onSpeechResult(event) {
        let finalTranscript = '';
        let interimTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            if (event.results[i].isFinal) {
                finalTranscript += transcript;
            } else {
                interimTranscript += transcript;
            }
        }
        
        // Track speech activity for pause detection in conversation mode
        if ((finalTranscript.trim() || interimTranscript.trim()) && this.conversationMode) {
            this.lastSpeechTime = Date.now();
            this.clearSilenceTimer();
            this.isWaitingForSpeech = false;
        }
        
        // Show interim results only in non-conversation mode for efficiency
        if (interimTranscript && !this.conversationMode) {
            const statusText = document.getElementById('statusText');
            if (statusText) {
                statusText.textContent = `Listening: "${interimTranscript}"`;
            }
        }
        
        if (finalTranscript.trim()) {
            const selectedLanguage = document.getElementById('languageSelect')?.value || 'en-US';
            console.log('üé§ Voice input detected:', finalTranscript);
            console.log('üéØ Current language setting:', selectedLanguage);
            console.log('üéØ Current conversation mode:', this.conversationMode);
            console.log('üéØ Current recording state:', this.isRecording);
            console.log('üéØ Current speaking state:', this.isSpeaking);
            
            // In conversation mode, keep listening while processing
            if (this.conversationMode) {
                // Stop current recording to process the message
                this.stopRecording();
                console.log('üéØ Conversation mode: Processing message and will restart listening after response');
                // Process immediately for real-time conversation
                this.processUserMessage(finalTranscript.trim(), true);
            } else {
                this.processUserMessage(finalTranscript.trim(), false);
                this.stopRecording();
            }
        }
    }
    
    onRecordingError(event) {
        console.error('Speech recognition error:', event.error);
        
        // In conversation mode, handle errors more gracefully
        if (this.conversationMode && event.error === 'no-speech') {
            // No-speech error is expected in conversation mode during pauses
            console.log('üéØ Conversation mode: No-speech detected, continuing to listen...');
            setTimeout(() => {
                if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                    this.startRecording();
                }
            }, 500);
            return;
        }
        
        this.onRecordingEnd();
        
        let errorMessage = 'Speech recognition issue: ';
        let suggestion = '';
        
        switch(event.error) {
            case 'no-speech':
                errorMessage += 'No speech was detected.';
                suggestion = 'Please speak clearly and try again. Make sure you\'re close to your microphone.';
                break;
            case 'audio-capture':
                errorMessage += 'Microphone access is not available.';
                suggestion = 'Please check your microphone connection and browser permissions.';
                break;
            case 'not-allowed':
                errorMessage += 'Microphone permission was denied.';
                suggestion = 'Please allow microphone access in your browser settings to use voice features.';
                break;
            case 'network':
                errorMessage += 'Network connection issue.';
                suggestion = 'Please check your internet connection and try again.';
                break;
            default:
                errorMessage += event.error;
                suggestion = 'Please try again or refresh the page if the problem persists.';
        }
        
        this.showMessage('ai', `${errorMessage} ${suggestion}`);
    }
    
    async processUserMessage(text, autoSpeak = false) {
        console.log('üöÄ processUserMessage called with:', text, 'autoSpeak:', autoSpeak);
        
        // Clear silence timer since user is actively speaking
        if (this.conversationMode) {
            this.clearSilenceTimer();
            this.isWaitingForSpeech = false;
        }
        
        // Show user message
        this.showMessage('user', text);
        console.log('‚úÖ User message displayed');
        
        // Update status for real-time feedback
        const statusText = document.getElementById('statusText');
        if (statusText) statusText.textContent = 'Processing your message...';
        
        // Analyze speech and get AI response
        try {
            console.log('üì° Making API call to /api/voice-chat/analyze');
            const selectedLanguage = document.getElementById('languageSelect')?.value || 'en-US';
            console.log('üì° API Request data:', { message: text, language: selectedLanguage });
            const response = await fetch('/api/voice-chat/analyze', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    message: text,
                    timestamp: new Date().toISOString(),
                    language: selectedLanguage
                })
            });
            
            console.log('üì° API Response status:', response.status);
            
            if (!response.ok) {
                throw new Error(`Network response was not ok: ${response.status}`);
            }
            
            const data = await response.json();
            console.log('üìä API Response data:', data);
            
            // Update analysis display
            this.updateAnalysisDisplay(data.analysis);
            console.log('üìä Analysis display updated');
            
            // Show AI response
            console.log('ü§ñ AI Response to display:', data.response);
            this.showMessage('ai', data.response);
            console.log('‚úÖ AI message displayed');
            
            // Store response for TTS
            this.lastAIResponse = data.response;
            
            // Enable speak button
            const speakBtn = document.getElementById('speakBtn');
            if (speakBtn) {
                speakBtn.disabled = false;
                speakBtn.textContent = 'üîä Speak Response';
            }
            
            // Auto-speak response for real-time conversation
            if ((autoSpeak || this.conversationMode) && data.response && this.synthesis) {
                console.log('üîä Auto-speaking response for conversation mode');
                if (statusText) statusText.textContent = 'Speaking response...';
                
                // Immediate response for better conversation flow
                this.speakResponse(data.response, () => {
                    // After speaking, just wait for user to respond
                    if (this.conversationMode) {
                        console.log('üé§ Waiting for user response - restarting listening');
                        if (statusText) statusText.textContent = 'üé§ Listening... Speak when ready';
                        
                        // Enhanced auto-restart for real-time conversation
                        const selectedLanguage = document.getElementById('languageSelect')?.value || 'en-US';
                        const isIndianLanguage = selectedLanguage.includes('-IN');
                        const restartDelay = isIndianLanguage ? 1500 : 1000; // Slightly longer delay for Indian languages
                        
                        setTimeout(() => {
                            if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                                console.log(`üîÑ Auto-restarting recording for user response (${selectedLanguage})`);
                                if (isIndianLanguage) {
                                    console.log('üéØ Enhanced settings for Indian language conversation');
                                }
                                this.startRecording();
                                this.startSilenceDetection();
                            }
                        }, restartDelay);
                    } else {
                        if (statusText) statusText.textContent = 'Ready - Click microphone to speak';
                    }
                });
            } else {
                if (statusText) statusText.textContent = this.conversationMode ? 'üéØ Conversation mode ready' : 'Ready - Click microphone to speak';
                
                // If conversation mode is active but not speaking, ensure we're listening
                if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                    setTimeout(() => {
                        if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                            console.log('üîÑ Ensuring conversation mode is listening');
                            this.startRecording();
                            this.startSilenceDetection();
                        }
                    }, 1000);
                }
            }
            console.log('üîä Processing complete');
            
        } catch (error) {
            console.error('‚ùå Error processing message:', error);
            this.showMessage('ai', 'I apologize, but I encountered an error processing your message. Please try again.');
            if (statusText) statusText.textContent = 'Error - Click microphone to try again';
        }
    }
    
    showMessage(sender, text) {
        const chatMessages = document.getElementById('chatMessages');
        const messageDiv = document.createElement('div');
        const timestamp = new Date().toLocaleTimeString([], {hour: '2-digit', minute:'2-digit'});
        
        messageDiv.className = `${sender}-message message-bubble rounded-xl p-4 max-w-[80%] ${sender === 'user' ? 'ml-auto' : ''}`;
        
        messageDiv.innerHTML = `
            <div class="flex items-start space-x-3 ${sender === 'user' ? 'flex-row-reverse space-x-reverse' : ''}">
                <div class="w-8 h-8 ${sender === 'ai' ? 'bg-green-500' : 'bg-purple-500'} rounded-full flex items-center justify-center text-white font-semibold">
                    ${sender === 'ai' ? 'AI' : 'YOU'}
                </div>
                <div class="${sender === 'user' ? 'text-right' : ''}">
                    <p class="text-white">${text}</p>
                    <span class="text-xs text-gray-400 mt-2 block">${timestamp}</span>
                </div>
            </div>
        `;
        
        chatMessages.appendChild(messageDiv);
        chatMessages.scrollTop = chatMessages.scrollHeight;
        
        this.messages.push({sender, text, timestamp});
        this.updateSessionStats();
    }
    
    updateAnalysisDisplay(analysis) {
        // Update sentiment
        const sentimentDisplay = document.getElementById('sentimentDisplay');
        const sentiment = analysis.sentiment || 'neutral';
        sentimentDisplay.textContent = sentiment.charAt(0).toUpperCase() + sentiment.slice(1);
        sentimentDisplay.className = sentiment === 'positive' ? 'text-lg font-semibold sentiment-positive' : 
                                   sentiment === 'negative' ? 'text-lg font-semibold sentiment-negative' : 
                                   'text-lg font-semibold sentiment-neutral';
        
        // Update confidence
        const confidenceBar = document.getElementById('confidenceBar');
        const confidenceText = document.getElementById('confidenceText');
        const confidence = Math.round((analysis.confidence || 0) * 100);
        confidenceBar.style.width = confidence + '%';
        confidenceText.textContent = confidence + '%';
        
        // Update emotion
        document.getElementById('emotionDisplay').textContent = analysis.emotion || 'Neutral';
        
        // Update keywords
        const keywordsDisplay = document.getElementById('keywordsDisplay');
        keywordsDisplay.innerHTML = '';
        if (analysis.keywords && analysis.keywords.length > 0) {
            analysis.keywords.forEach(keyword => {
                const keywordSpan = document.createElement('span');
                keywordSpan.className = 'px-2 py-1 bg-purple-600 text-white text-xs rounded-full';
                keywordSpan.textContent = keyword;
                keywordsDisplay.appendChild(keywordSpan);
            });
        }
        
        // Update average sentiment
        this.totalSentiment += analysis.sentiment_score || 0;
        this.sentimentCount++;
        const avgSentiment = this.totalSentiment / this.sentimentCount;
        document.getElementById('avgSentiment').textContent = 
            avgSentiment > 0.1 ? 'Positive' : avgSentiment < -0.1 ? 'Negative' : 'Neutral';
    }
    
    updateSessionStats() {
        document.getElementById('messageCount').textContent = this.messages.filter(m => m.sender === 'user').length;
        
        const duration = Math.floor((Date.now() - this.sessionStart) / 1000);
        const minutes = Math.floor(duration / 60);
        const seconds = duration % 60;
        document.getElementById('sessionDuration').textContent = `${minutes}:${seconds.toString().padStart(2, '0')}`;
    }
    
    speakResponse(text, onComplete = null) {
        if (!text || !this.synthesis) {
            console.log('‚ùå TTS not available:', { text: !!text, synthesis: !!this.synthesis });
            if (onComplete) onComplete();
            return;
        }
        
        // Cancel any ongoing speech
        this.synthesis.cancel();
        
        try {
            // Force voices to load if not already loaded
            const voices = this.synthesis.getVoices();
            if (voices.length === 0) {
                console.log('‚ö†Ô∏è No voices loaded yet, waiting for voices...');
                // Wait for voices to load
                this.synthesis.addEventListener('voiceschanged', () => {
                    console.log('üîä Voices loaded, retrying TTS');
                    this.speakResponse(text, onComplete);
                }, { once: true });
                return;
            }
            
            const utterance = new SpeechSynthesisUtterance(text);
            // Optimize speech rate for conversation mode
            utterance.rate = this.conversationMode ? 1.0 : 0.9; // Normal rate for better Telugu pronunciation
            utterance.pitch = 1.0;
            utterance.volume = 1.0; // Full volume
            
            // Get current language selection
            const selectedLanguage = document.getElementById('languageSelect')?.value || 'en-US';
            console.log('üîä TTS Request - Language:', selectedLanguage, 'Text length:', text.length);
            
            // Set language and find appropriate voice
            this.configureVoiceForLanguage(utterance, selectedLanguage);
            
            // Add event listeners with enhanced debugging
            utterance.onstart = () => {
                this.isSpeaking = true;
                console.log('üîä ‚úÖ TTS STARTED - Voice:', utterance.voice?.name || 'System default', 'Lang:', utterance.lang);
            };
            
            utterance.onend = () => {
                this.isSpeaking = false;
                console.log('üîä ‚úÖ TTS COMPLETED SUCCESSFULLY');
                if (onComplete) onComplete();
            };
            
            utterance.onerror = (event) => {
                console.error('üîä ‚ùå TTS ERROR:', event.error, event);
                console.error('üîä Error details:', {
                    error: event.error,
                    text: utterance.text?.substring(0, 50) + '...',
                    voice: utterance.voice?.name,
                    lang: utterance.lang
                });
                this.isSpeaking = false;
                if (onComplete) onComplete();
            };
            
            // Final TTS configuration check before speaking
            console.log('üîä === FINAL TTS CONFIGURATION ===');
            console.log('üîä Text to speak:', text.substring(0, 100) + (text.length > 100 ? '...' : ''));
            console.log('üîä Selected voice:', utterance.voice?.name || 'System default');
            console.log('üîä Language:', utterance.lang);
            console.log('üîä Rate:', utterance.rate, 'Pitch:', utterance.pitch, 'Volume:', utterance.volume);
            
            // Speak the utterance
            console.log('üîä üé§ ATTEMPTING TO SPEAK...');
            this.synthesis.speak(utterance);
            
        } catch (error) {
            console.error('Error in TTS:', error);
            this.isSpeaking = false;
            if (onComplete) onComplete();
        }
    }
    
    configureVoiceForLanguage(utterance, selectedLanguage) {
        const voices = this.synthesis.getVoices();
        let preferredVoice = null;
        
        console.log('üîä Configuring voice for language:', selectedLanguage);
        
        // Language-specific voice selection
        if (selectedLanguage.startsWith('hi-')) {
            preferredVoice = voices.find(voice => 
                voice.lang.toLowerCase().includes('hi-in') || 
                voice.lang.toLowerCase().includes('hi_in') ||
                voice.name.toLowerCase().includes('hindi') ||
                voice.name.toLowerCase().includes('hemant') ||
                voice.name.toLowerCase().includes('kalpana')
            );
            utterance.lang = 'hi-IN';
        } else if (selectedLanguage.startsWith('te-')) {
            console.log('üîä === TELUGU TTS CONFIGURATION ===');
            console.log('üîä Total available voices:', voices.length);
            console.log('üîä Available voices:', voices.map(v => `${v.name} (${v.lang}) [${v.localService ? 'Local' : 'Remote'}]`));
            
            // Enhanced Telugu voice search with multiple fallback strategies
            const teluguPatterns = [
                // Primary Telugu language matches
                { name: 'Exact te-IN', test: voice => voice.lang === 'te-IN' },
                { name: 'Exact te_IN', test: voice => voice.lang === 'te_IN' },
                { name: 'Lang starts te-', test: voice => voice.lang.toLowerCase().startsWith('te-') },
                { name: 'Lang starts te_', test: voice => voice.lang.toLowerCase().startsWith('te_') },
                { name: 'Lang equals te', test: voice => voice.lang.toLowerCase() === 'te' },
                
                // Voice name patterns
                { name: 'Name contains telugu', test: voice => voice.name.toLowerCase().includes('telugu') },
                { name: 'Name contains heera', test: voice => voice.name.toLowerCase().includes('heera') },
                { name: 'Name contains chitra', test: voice => voice.name.toLowerCase().includes('chitra') },
                
                // Microsoft voices
                { name: 'Microsoft + te lang', test: voice => voice.name.toLowerCase().includes('microsoft') && voice.lang.toLowerCase().includes('te') },
                { name: 'Microsoft Telugu', test: voice => voice.name.toLowerCase().includes('microsoft') && voice.name.toLowerCase().includes('telugu') },
                
                // Fallback patterns
                { name: 'Any te in lang', test: voice => voice.lang.toLowerCase().includes('te') },
                { name: 'Indian voices', test: voice => voice.lang.includes('-IN') || voice.name.toLowerCase().includes('indian') }
            ];
            
            // Try each pattern until we find a voice
            for (const pattern of teluguPatterns) {
                preferredVoice = voices.find(pattern.test);
                if (preferredVoice) {
                    console.log(`üîä ‚úÖ Telugu voice found using "${pattern.name}":`, preferredVoice.name, '(', preferredVoice.lang, ')');
                    break;
                } else {
                    console.log(`üîä ‚ùå No voice found for pattern: ${pattern.name}`);
                }
            }
            
            utterance.lang = 'te-IN';
            
            if (preferredVoice) {
                console.log('üîä ‚úÖ SELECTED TELUGU VOICE:', preferredVoice.name, '(', preferredVoice.lang, ')');
                console.log('üîä Voice details:', {
                    name: preferredVoice.name,
                    lang: preferredVoice.lang,
                    localService: preferredVoice.localService,
                    default: preferredVoice.default,
                    voiceURI: preferredVoice.voiceURI
                });
            } else {
                console.log('üîä ‚ö†Ô∏è NO TELUGU VOICE FOUND - Using system default');
                console.log('üîä Recommendation: Install Telugu language pack or use Edge/Chrome browser');
                console.log('üîä Will attempt TTS with system default voice and te-IN language setting');
            }
        } else if (selectedLanguage.startsWith('kn-')) {
            preferredVoice = voices.find(voice => 
                voice.lang.toLowerCase().includes('kn-in') || 
                voice.lang.toLowerCase().includes('kn_in') ||
                voice.name.toLowerCase().includes('kannada') ||
                voice.name.toLowerCase().includes('shankar')
            );
            utterance.lang = 'kn-IN';
        } else {
            // English voices
            preferredVoice = voices.find(voice => voice.lang.includes('en'));
            utterance.lang = selectedLanguage;
        }
        
        // Fallback for Telugu if specific voice not found
        if (!preferredVoice && selectedLanguage.startsWith('te-')) {
            preferredVoice = voices.find(voice => 
                voice.lang.includes('te') || voice.lang.includes('TE')
            );
        }
        
        if (preferredVoice) {
            utterance.voice = preferredVoice;
            console.log('üîä Using voice:', preferredVoice.name, preferredVoice.lang);
        }
    }

    speakLastResponse() {
        if (!this.lastAIResponse) {
            this.showMessage('ai', 'No response available to speak. Please have a conversation first.');
            return;
        }
        
        const speakBtn = document.getElementById('speakBtn');
        
        // Check if we're currently speaking
        if (this.isSpeaking) {
            this.synthesis.cancel();
            this.isSpeaking = false;
            speakBtn.textContent = 'üîä Speak Response';
            speakBtn.disabled = false;
            return;
        }
        
        speakBtn.textContent = 'üîá Stop Speaking';
        this.speakResponse(this.lastAIResponse, () => {
            speakBtn.textContent = 'üîä Speak Response';
        });
    }
    
    clearChat() {
        document.getElementById('chatMessages').innerHTML = `
            <div class="ai-message message-bubble rounded-xl p-4 max-w-[80%]">
                <div class="flex items-start space-x-3">
                    <div class="w-8 h-8 bg-green-500 rounded-full flex items-center justify-center text-white font-semibold">
                        AI
                    </div>
                    <div>
                        <p class="text-white">Hello! I'm your AI voice mentor. Click the microphone to start speaking, and I'll analyze your speech and provide helpful guidance. How are you feeling today?</p>
                        <span class="text-xs text-gray-400 mt-2 block">Just now</span>
                    </div>
                </div>
            </div>
        `;
        
        this.messages = [];
        this.sessionStart = Date.now();
        this.totalSentiment = 0;
        this.sentimentCount = 0;
        this.lastAIResponse = null;
        this.isSpeaking = false;
        
        // Reset TTS button
        const speakBtn = document.getElementById('speakBtn');
        if (speakBtn) {
            speakBtn.disabled = true;
            speakBtn.textContent = 'üîä Speak Response';
        }
        
        // Cancel any ongoing speech
        if (this.synthesis) {
            this.synthesis.cancel();
        }
        
        // Reset analysis display
        document.getElementById('sentimentDisplay').textContent = 'Neutral';
        document.getElementById('sentimentDisplay').className = 'text-lg font-semibold sentiment-neutral';
        document.getElementById('confidenceBar').style.width = '0%';
        document.getElementById('confidenceText').textContent = '0%';
        document.getElementById('emotionDisplay').textContent = '-';
        document.getElementById('keywordsDisplay').innerHTML = '';
        document.getElementById('avgSentiment').textContent = 'Neutral';
        
        this.updateSessionStats();
    }
    
    async testMicrophone() {
        console.log('üé§ Testing microphone...');
        this.showMessage('ai', 'üé§ Testing microphone... Please say "Hello" when I start listening.');
        
        if (!this.recognition) {
            this.showMessage('ai', '‚ùå Speech recognition not available in your browser.');
            return;
        }
        
        try {
            // Check microphone permissions first
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log('‚úÖ Microphone access granted');
                stream.getTracks().forEach(track => track.stop());
            }
            
            // Test speech recognition
            console.log('üé§ Starting speech recognition test...');
            this.showMessage('ai', 'üé§ Microphone test started! Say "Hello" now...');
            
            const testRecognition = new (window.webkitSpeechRecognition || window.SpeechRecognition)();
            testRecognition.continuous = false;
            testRecognition.interimResults = false;
            testRecognition.lang = 'en-US';
            
            testRecognition.onstart = () => {
                console.log('‚úÖ Test recognition started successfully');
                this.showMessage('ai', 'üé§ Test listening active - say "Hello" now!');
            };
            
            testRecognition.onresult = (event) => {
                const result = event.results[0][0].transcript;
                console.log('‚úÖ Speech recognition test result:', result);
                this.showMessage('ai', `‚úÖ Microphone test successful! I heard: "${result}"`);
            };
            
            testRecognition.onerror = (event) => {
                console.error('‚ùå Speech recognition test error:', event.error);
                this.showMessage('ai', `‚ùå Microphone test failed: ${event.error}. Please check your microphone permissions and try again.`);
            };
            
            testRecognition.onend = () => {
                console.log('üé§ Speech recognition test ended');
            };
            
            testRecognition.start();
            
        } catch (error) {
            console.error('‚ùå Microphone test error:', error);
            this.showMessage('ai', `‚ùå Microphone test failed: ${error.message}. Please allow microphone access and refresh the page.`);
        }
    }
    
    startRecordingTimer() {
        let seconds = 0;
        this.recordingTimer = setInterval(() => {
            seconds++;
            const minutes = Math.floor(seconds / 60);
            const secs = seconds % 60;
            document.getElementById('recordingTime').textContent = 
                `${minutes}:${secs.toString().padStart(2, '0')}`;
            
            // Update progress bar (max 60 seconds)
            const progress = Math.min((seconds / 60) * 100, 100);
            document.getElementById('progressBar').style.width = progress + '%';
        }, 1000);
    }
    
    // DISABLED: No automatic conversation starters
    startConversationWithQuestion(languageCode) {
        console.log('üö´ Automatic conversation questions DISABLED - waiting for user to speak first');
        return; // Don't ask opening questions automatically
        
        /*
        console.log('üéØ Starting conversation with opening question in:', languageCode);
        
        const openingQuestions = {
            'en-US': "Hello! I'm excited to chat with you today. How are you feeling right now? What's on your mind?",
            'en-GB': "Hello! I'm excited to chat with you today. How are you feeling right now? What's on your mind?",
            'hi-IN': "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§Ü‡§ú ‡§Ü‡§™‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§Ö‡§≠‡•Ä ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç? ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?",
            'te-IN': "‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞à‡∞∞‡±ã‡∞ú‡±Å ‡∞Æ‡±Ä‡∞§‡±ã ‡∞ö‡∞æ‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞®‡±á‡∞®‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞â‡∞§‡±ç‡∞∏‡∞æ‡∞π‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞é‡∞≤‡∞æ ‡∞Ö‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å? ‡∞Æ‡±Ä ‡∞Æ‡∞®‡∞∏‡±Å‡∞≤‡±ã ‡∞è‡∞Æ‡∞ø ‡∞â‡∞Ç‡∞¶‡∞ø?",
            'kn-IN': "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞! ‡≤á‡≤Ç‡≤¶‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤ö‡≤æ‡≤ü‡≥ç ‡≤Æ‡≤æ‡≤°‡≤≤‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤â‡≤§‡≥ç‡≤∏‡≤æ‡≤π‡≤¶‡≤ø‡≤Ç‡≤¶‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤á‡≤¶‡≥Ä‡≤ó ‡≤π‡≥á‡≤ó‡≥Ü ‡≤Ö‡≤®‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü? ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤®‡≤∏‡≥ç‡≤∏‡≤ø‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤è‡≤®‡≤ø‡≤¶‡≥Ü?"
        };
        
        const question = openingQuestions[languageCode] || openingQuestions['en-US'];
        
        setTimeout(() => {
            if (this.conversationMode) {
                console.log('ü§ñ Asking opening question:', question);
                this.showMessage('ai', question);
                this.speakResponse(question, () => {
                    // After asking question, ensure we're listening
                    if (this.conversationMode && !this.isRecording) {
                        setTimeout(() => this.startRecording(), 500);
                    }
                });
            }
        }, 1000);
        */
    }
    
    askFollowUpQuestion() {
        // DISABLED: No automatic follow-up questions
        console.log('üö´ Follow-up questions DISABLED - waiting for user to continue conversation');
        return;
        
        /*
        if (!this.conversationMode) return;
        
        const selectedLanguage = document.getElementById('languageSelect')?.value || 'en-US';
        
        const followUpQuestions = {
            'en-US': [
                "Tell me more about that. How does it make you feel?",
                "That's interesting. What else would you like to share?",
                "I'd love to hear more. What's been on your mind lately?",
                "How has your day been so far?",
                "What would you like to talk about next?"
            ],
            'en-GB': [
                "Tell me more about that. How does it make you feel?",
                "That's interesting. What else would you like to share?",
                "I'd love to hear more. What's been on your mind lately?",
                "How has your day been so far?",
                "What would you like to talk about next?"
            ],
            'hi-IN': [
                "‡§á‡§∏‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§¨‡§§‡§æ‡§á‡§è‡•§ ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•à‡§∏‡§æ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à?",
                "‡§Ø‡§π ‡§¶‡§ø‡§≤‡§ö‡§∏‡•ç‡§™ ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§î‡§∞ ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á?",
                "‡§Æ‡•à‡§Ç ‡§î‡§∞ ‡§∏‡•Å‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•Ç‡§Ç‡§ó‡§æ‡•§ ‡§π‡§æ‡§≤ ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§Æ‡§® ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?",
                "‡§Ü‡§ú ‡§§‡§ï ‡§Ü‡§™‡§ï‡§æ ‡§¶‡§ø‡§® ‡§ï‡•à‡§∏‡§æ ‡§∞‡§π‡§æ?",
                "‡§Ü‡§™ ‡§Ü‡§ó‡•á ‡§ï‡§ø‡§∏ ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á?"
            ],
            'te-IN': [
                "‡∞¶‡∞æ‡∞®‡∞ø ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø. ‡∞Ö‡∞¶‡∞ø ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞é‡∞≤‡∞æ ‡∞Ö‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø?",
                "‡∞Ö‡∞¶‡∞ø ‡∞Ü‡∞∏‡∞ï‡±ç‡∞§‡∞ø‡∞ï‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞á‡∞Ç‡∞ï‡∞æ ‡∞è‡∞Æ‡∞ø ‡∞™‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?",
                "‡∞®‡±á‡∞®‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞µ‡∞ø‡∞®‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å. ‡∞á‡∞ü‡±Ä‡∞µ‡∞≤ ‡∞Æ‡±Ä ‡∞Æ‡∞®‡∞∏‡±Å‡∞≤‡±ã ‡∞è‡∞Æ‡∞ø ‡∞â‡∞Ç‡∞¶‡∞ø?",
                "‡∞á‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞µ‡∞∞‡∞ï‡±Å ‡∞Æ‡±Ä ‡∞∞‡±ã‡∞ú‡±Å ‡∞é‡∞≤‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø?",
                "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?"
            ],
            'kn-IN': [
                "‡≤Ö‡≤¶‡≤∞ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤á‡≤®‡≥ç‡≤®‡≤∑‡≥ç‡≤ü‡≥Å ‡≤π‡≥á‡≤≥‡≤ø. ‡≤Ö‡≤¶‡≥Å ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤π‡≥á‡≤ó‡≥Ü ‡≤Ö‡≤®‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü?",
                "‡≤Ö‡≤¶‡≥Å ‡≤ï‡≥Å‡≤§‡≥Ç‡≤π‡≤≤‡≤ï‡≤æ‡≤∞‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤á‡≤®‡≥ç‡≤®‡≥á‡≤®‡≥Å ‡≤π‡≤Ç‡≤ö‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å ‡≤¨‡≤Ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥Ä‡≤∞‡≤ø?",
                "‡≤®‡≤æ‡≤®‡≥Å ‡≤á‡≤®‡≥ç‡≤®‡≤∑‡≥ç‡≤ü‡≥Å ‡≤ï‡≥á‡≤≥‡≤≤‡≥Å ‡≤á‡≤∑‡≥ç‡≤ü‡≤™‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü. ‡≤á‡≤§‡≥ç‡≤§‡≥Ä‡≤ö‡≥Ü‡≤ó‡≥Ü ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤®‡≤∏‡≥ç‡≤∏‡≤ø‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤è‡≤®‡≤ø‡≤¶‡≥Ü?",
                "‡≤á‡≤≤‡≥ç‡≤≤‡≤ø‡≤Ø‡≤µ‡≤∞‡≥Ü‡≤ó‡≥Ü ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤¶‡≤ø‡≤® ‡≤π‡≥á‡≤ó‡≤ø‡≤§‡≥ç‡≤§‡≥Å?",
                "‡≤®‡≥Ä‡≤µ‡≥Å ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Ü ‡≤Ø‡≤æ‡≤µ ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤≤‡≥Å ‡≤¨‡≤Ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥Ä‡≤∞‡≤ø?"
            ]
        };
        
        const questions = followUpQuestions[selectedLanguage] || followUpQuestions['en-US'];
        const randomQuestion = questions[Math.floor(Math.random() * questions.length)];
        
        setTimeout(() => {
            if (this.conversationMode) {
                console.log('ü§ñ Asking follow-up question:', randomQuestion);
                this.showMessage('ai', randomQuestion);
                this.speakResponse(randomQuestion);
            }
        }, 2000); // Give user time to process the previous response
        */
    }
    
    startSilenceDetection() {
        if (!this.conversationMode) return;
        
        this.clearSilenceTimer();
        this.lastSpeechTime = Date.now();
        this.isWaitingForSpeech = true;
        
        // DISABLED: No automatic prompts - wait for user to speak
        console.log('ü§´ Silence detection active - waiting for user input (no auto-prompts)');
        
        // Keep the timer but don't trigger automatic prompts
        this.silenceTimer = setTimeout(() => {
            if (this.conversationMode && this.isWaitingForSpeech && !this.isSpeaking) {
                console.log('ü§î Long silence detected, but NOT providing automatic prompt (user-initiated only)');
                // Just log but don't call provideAutomaticPrompt()
            }
        }, this.silenceThreshold);
    }
    
    clearSilenceTimer() {
        if (this.silenceTimer) {
            clearTimeout(this.silenceTimer);
            this.silenceTimer = null;
        }
    }
    
    async provideAutomaticPrompt() {
        // DISABLED: No automatic prompts - this ensures real-time conversation waits for user
        console.log('üö´ Automatic prompt DISABLED - waiting for user to initiate conversation');
        return;
        
        // Old automatic prompt code is disabled to prevent automatic responses
        /*
        const selectedLanguage = document.getElementById('languageSelect')?.value || 'en-US';
        
        try {
            // Get contextual prompt from server
            const response = await fetch('/api/voice-chat/auto-prompt', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    language: selectedLanguage,
                    context: this.determineConversationContext()
                })
            });
            
            const data = await response.json();
            const automaticPrompt = data.success ? data.prompt : this.getAutomaticPrompts(selectedLanguage)[0];
            
            console.log('ü§ñ Providing automatic prompt:', automaticPrompt);
            this.showMessage('ai', automaticPrompt);
            
            // Speak the prompt automatically
            if (this.synthesis) {
                this.speakResponse(automaticPrompt, () => {
                    // After speaking prompt, continue listening
                    if (this.conversationMode) {
                        setTimeout(() => {
                            if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                                this.startRecording();
                            }
                        }, 500);
                    }
                });
            }
        } catch (error) {
            console.error('Error getting automatic prompt:', error);
            // Fallback to local prompts
            const prompts = this.getAutomaticPrompts(selectedLanguage);
            const randomPrompt = prompts[Math.floor(Math.random() * prompts.length)];
            
            console.log('ü§ñ Providing fallback automatic prompt:', randomPrompt);
            this.showMessage('ai', randomPrompt);
            
            if (this.synthesis) {
                this.speakResponse(randomPrompt, () => {
                    if (this.conversationMode) {
                        setTimeout(() => {
                            if (this.conversationMode && !this.isRecording && !this.isSpeaking) {
                                this.startRecording();
                            }
                        }, 500);
                    }
                });
            }
        }
        */
    }
    
    determineConversationContext() {
        // Analyze recent messages to determine context
        const recentMessages = this.messages.slice(-3); // Look at last 3 messages
        let context = 'general';
        
        if (recentMessages.length > 0) {
            const messageText = recentMessages.map(m => m.text).join(' ').toLowerCase();
            
            if (messageText.includes('study') || messageText.includes('exam') || messageText.includes('college') || 
                messageText.includes('‡∞ö‡∞¶‡±Å‡∞µ‡±Å') || messageText.includes('‡∞™‡∞∞‡±Ä‡∞ï‡•ç‡§∑‡§æ') || messageText.includes('‡§Ö‡§ß‡•ç‡§Ø‡§Ø‡§®')) {
                context = 'study';
            } else if (messageText.includes('wellness') || messageText.includes('mental') || messageText.includes('health') ||
                       messageText.includes('stress') || messageText.includes('‡∞Æ‡∞æ‡∞®‡∞∏‡∞ø‡∞ï') || messageText.includes('‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø')) {
                context = 'wellness';
            }
        }
        
        console.log('üìä Determined conversation context:', context);
        return context;
    }
    
    getAutomaticPrompts(language) {
        const prompts = {
            'en-US': [
                "Is there anything else on your mind?",
                "How are you feeling about what we just discussed?",
                "Would you like to share more about your thoughts?",
                "I'm here to listen. What would you like to talk about?",
                "Feel free to continue sharing whenever you're ready.",
                "Is there something specific you'd like to explore further?"
            ],
            'en-GB': [
                "Is there anything else on your mind?",
                "How are you feeling about what we just discussed?",
                "Would you like to share more about your thoughts?",
                "I'm here to listen. What would you like to talk about?",
                "Feel free to continue sharing whenever you're ready.",
                "Is there something specific you'd like to explore further?"
            ],
            'hi-IN': [
                "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§Æ‡§® ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§π‡•à?",
                "‡§Ü‡§™ ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç?",
                "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•á ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?",
                "‡§Æ‡•à‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§∏‡•Å‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?",
                "‡§ú‡§¨ ‡§Ü‡§™ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§Ç ‡§§‡•ã ‡§¨‡•á‡§ù‡§ø‡§ù‡§ï ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡•á‡§Ç‡•§",
                "‡§ï‡•ç‡§Ø‡§æ ‡§ï‡•Å‡§õ ‡§ñ‡§æ‡§∏ ‡§π‡•à ‡§ú‡§ø‡§∏‡•á ‡§Ü‡§™ ‡§î‡§∞ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?"
            ],
            'te-IN': [
                "‡∞Æ‡±Ä ‡∞Æ‡∞®‡∞∏‡±Å‡∞≤‡±ã ‡∞á‡∞Ç‡∞ï‡∞æ ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞â‡∞Ç‡∞¶‡∞æ?",
                "‡∞Æ‡∞®‡∞Ç ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞ø‡∞® ‡∞¶‡∞æ‡∞®‡∞ø ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞é‡∞≤‡∞æ ‡∞Ö‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø?",
                "‡∞Æ‡±Ä ‡∞Ü‡∞≤‡±ã‡∞ö‡∞®‡∞≤‡∞®‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞™‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡∞ø ‡∞Ö‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞æ?",
                "‡∞®‡±á‡∞®‡±Å ‡∞µ‡∞ø‡∞®‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è‡∞Æ‡∞ø ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞æ‡∞≤‡∞®‡∞ø ‡∞Ö‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?",
                "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞∏‡±ç‡∞µ‡±á‡∞ö‡±ç‡∞õ‡∞ó‡∞æ ‡∞™‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø‡•§",
                "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡∞ø ‡∞Ö‡∞®‡±Å‡∞ï‡±Å‡∞®‡±á ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï‡∞Æ‡±à‡∞®‡∞¶‡∞ø ‡∞â‡∞Ç‡∞¶‡∞æ?"
            ],
            'kn-IN': [
                "‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤®‡≤∏‡≥ç‡≤∏‡≤ø‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤á‡≤®‡≥ç‡≤®‡≥á‡≤®‡≤æ‡≤¶‡≤∞‡≥Ç ‡≤á‡≤¶‡≥Ü‡≤Ø‡≥á?",
                "‡≤®‡≤æ‡≤µ‡≥Å ‡≤à‡≤ó ‡≤Æ‡≤æ‡≤§‡≤æ‡≤°‡≤ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤π‡≥á‡≤ó‡≥Ü ‡≤Ö‡≤®‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü?",
                "‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ü‡≤≤‡≥ã‡≤ö‡≤®‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å ‡≤π‡≤Ç‡≤ö‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å ‡≤¨‡≤Ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥Ä‡≤∞‡≤æ?",
                "‡≤®‡≤æ‡≤®‡≥Å ‡≤ï‡≥á‡≤≥‡≤≤‡≥Å ‡≤á‡≤≤‡≥ç‡≤≤‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤è‡≤®‡≥Å ‡≤Æ‡≤æ‡≤§‡≤æ‡≤°‡≤≤‡≥Å ‡≤¨‡≤Ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥Ä‡≤∞‡≤ø?",
                "‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤µ‡≤æ‡≤¶‡≤æ‡≤ó ‡≤Æ‡≥Å‡≤ï‡≥ç‡≤§‡≤µ‡≤æ‡≤ó‡≤ø ‡≤π‡≤Ç‡≤ö‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤ø‡•§",
                "‡≤®‡≥Ä‡≤µ‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≤∑‡≥ç‡≤ü‡≥Å ‡≤Ö‡≤®‡≥ç‡≤µ‡≥á‡≤∑‡≤ø‡≤∏‡≤≤‡≥Å ‡≤¨‡≤Ø‡≤∏‡≥Å‡≤µ ‡≤è‡≤®‡≤æ‡≤¶‡≤∞‡≥Ç ‡≤®‡≤ø‡≤∞‡≥ç‡≤¶‡≤ø‡≤∑‡≥ç‡≤ü‡≤µ‡≤æ‡≤¶‡≥Å‡≤¶‡≥Å ‡≤á‡≤¶‡≥Ü‡≤Ø‡≥á?"
            ]
        };
        
        return prompts[language] || prompts['en-US'];
    }
}

// Quick action functions
function askQuestion(question) {
    console.log('üéØ askQuestion called with:', question);
    if (window.voiceChat) {
        console.log('‚úÖ voiceChat instance found, calling processUserMessage');
        window.voiceChat.processUserMessage(question);
    } else {
        console.error('‚ùå voiceChat instance not found!');
    }
}

function requestAdvice() {
    console.log('üí° requestAdvice called');
    if (window.voiceChat) {
        console.log('‚úÖ voiceChat instance found, requesting advice');
        window.voiceChat.processUserMessage("Can you give me some advice based on our conversation?");
    } else {
        console.error('‚ùå voiceChat instance not found!');
    }
}

// Initialize voice chat when DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
    window.voiceChat = new VoiceAIChat();
});
</script>
{% endblock %}